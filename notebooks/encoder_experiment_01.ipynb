{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6e562d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "/home/spieterman/dev/projects/dwi-transformer/.venv/bin/python\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "# adjust this path if your repo is elsewhere\n",
    "proj_root = os.path.abspath(os.path.join(os.getcwd(), os.pardir))\n",
    "if proj_root not in sys.path:\n",
    "    sys.path.append(proj_root)\n",
    "\n",
    "# confirm device\n",
    "import torch\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using device:\", DEVICE)\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b402686d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shape of each 3D volume (after your resampling step)\n",
    "IMG_SHAPE = (150, 150, 150)\n",
    "\n",
    "# Latent dimension for all AEs\n",
    "LATENT_DIM = 128\n",
    "\n",
    "# Training settings\n",
    "BATCH_SIZE = 4\n",
    "LR = 1e-3\n",
    "EPOCHS = 5\n",
    "\n",
    "# Paths\n",
    "DATA_DIR = os.path.join(proj_root, \"data\", \"resampled_volumes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "646a7612",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import your model modules\n",
    "from models.custom_ae import Custom3dAE\n",
    "from models.monai_ae  import get_monai_ae\n",
    "#from models.resnet_ae import ResNetAE\n",
    "\n",
    "# Registry to swap models by name\n",
    "MODEL_REGISTRY = {\n",
    "    \"custom\": lambda: Custom3dAE(latent_dim=LATENT_DIM, in_shape=(1,*IMG_SHAPE)).to(DEVICE),\n",
    "    \"monai\":  lambda: get_monai_ae().to(DEVICE),\n",
    "    #\"resnet\": lambda: ResNetAE(latent_dim=LATENT_DIM).to(DEVICE),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ebccf72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Unique volume shapes found:\n",
      "(91, 109, 91, 26): 151 files\n",
      "(91, 109, 91): 239 files\n",
      "(91, 109, 91, 91): 61 files\n",
      "(91, 109, 91, 65): 9 files\n",
      "(91, 109, 91, 13): 5 files\n",
      "(91, 109, 91, 52): 1 file\n",
      "(91, 109, 91, 69): 2 files\n",
      "(91, 109, 91, 2): 8 files\n",
      "(91, 109, 91, 50): 1 file\n",
      "(91, 109, 91, 48): 1 file\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from collections import Counter\n",
    "import nibabel as nib\n",
    "\n",
    "# test_path = \"~/dev/projects/dwi-preprocessing/data/preproc/sub-OAS30001/ses-d0757/sub-OAS30001_ses-d0757_dwi_allruns.nii.gz\"\n",
    "DATA_DIR = \"~/dev/projects/dwi-preprocessing/data/preproc/\"   # adjust to your root folder\n",
    "\n",
    "def find_nifti_files(root_dir):\n",
    "    root_dir = os.path.abspath(os.path.expanduser(root_dir))\n",
    "    for dirpath, _, filenames in os.walk(root_dir):\n",
    "        for fn in filenames:\n",
    "            if fn.endswith((\".nii.gz\")):\n",
    "                yield os.path.join(dirpath, fn)\n",
    "\n",
    "shape_counts = Counter()\n",
    "errors = []\n",
    "\n",
    "for path in find_nifti_files(DATA_DIR):\n",
    "    try:\n",
    "        img = nib.load(path)\n",
    "        shape_counts[img.shape] += 1\n",
    "    except Exception as e:\n",
    "        errors.append((path, str(e)))\n",
    "\n",
    "# Display results\n",
    "print(\"🔍 Unique volume shapes found:\")\n",
    "for shape, count in shape_counts.items():\n",
    "    print(f\"{shape}: {count} file{'s' if count>1 else ''}\")\n",
    "\n",
    "if errors:\n",
    "    print(f\"\\n⚠️  {len(errors)} file(s) failed to load:\")\n",
    "    for p, err in errors[:5]:\n",
    "        print(f\"    - {p}: {err}\")\n",
    "    if len(errors)>5:\n",
    "        print(f\"    ... and {len(errors)-5} more\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b405a19b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 239/239 [11:33<00:00,  2.90s/it]\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np, nibabel as nib, json, argparse\n",
    "from tqdm import tqdm\n",
    "\n",
    "ROOT   = Path(\"/home/spieterman/dev/projects/dwi-preprocessing/data/preproc\")\n",
    "CACHE  = Path(\"/home/spieterman/dev/projects/dwi-transformer/data/encoder\")                                       # output root\n",
    "CACHE.mkdir(exist_ok=True)\n",
    "\n",
    "def find_sessions(root: Path):\n",
    "    return sorted(root.rglob(\"*_dwi_allruns.nii.gz\"))\n",
    "\n",
    "def normalise_dwi(dwi_data: np.ndarray, bvals: np.ndarray):\n",
    "    \"\"\"\n",
    "    Load a 4-D DWI series and apply robust, session-level gain and z-score normalisation.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dwi_path : Path\n",
    "        Path to the cleaned 4-D DWI NIfTI (shape [X,Y,Z,N]).\n",
    "    bval_path : Path\n",
    "        Path to the matching .bval file (one row of N b-values).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dwi_norm : ndarray (float32)\n",
    "        The fully normalised DWI data (same shape as input).\n",
    "    stats : dict\n",
    "        {\n",
    "          'gain': float,       # scale factor applied to align b0 median → 1.0\n",
    "          'mean': float,       # session-wide mean after gain scaling\n",
    "          'std':  float        # session-wide std  after gain scaling\n",
    "        }\n",
    "    \"\"\"\n",
    "\n",
    "    # 1) Identify all b0 volumes (b-value == 0)\n",
    "    b0_indices  = np.where(bvals == 0)[0]         # e.g. array([0, 10, 20])\n",
    "\n",
    "    # 2) Extract those b0 volumes and form a union-mask of nonzero voxels\n",
    "    #    (handles slight mis-alignments: if *any* run has signal, we treat it as brain)\n",
    "    b0_volumes = np.take(dwi_data, b0_indices, axis=3)  # shape (X, Y, Z, N_b0)\n",
    "    mask       = np.any(b0_volumes > 0, axis=3)         # boolean mask [X,Y,Z]\n",
    "\n",
    "    # 3) Remove any stray zero-intensity voxels inside the union mask\n",
    "    #    (e.g. holes due to warping) before computing the gain\n",
    "    b0_values  = b0_volumes[mask].ravel()\n",
    "    b0_values  = b0_values[b0_values > 0]               # drop zeros\n",
    "\n",
    "    # 4) SESSION-GAIN NORMALISATION:\n",
    "    #    Anchor the median of all b0 tissue intensities to 1.0,\n",
    "    #    removing scanner-/coil-level scale differences across sessions\n",
    "    gain       = 1.0 / (np.median(b0_values) + 1e-12)\n",
    "    dwi_scaled = dwi_data * gain\n",
    "\n",
    "    # 5) SESSION-WIDE Z-SCORE NORMALISATION:\n",
    "    #    Compute mean/std across all brain voxels in all volumes,\n",
    "    #    giving zero-mean/unit-variance inputs for the autoencoder,\n",
    "    #    yet preserving relative shell attenuation patterns.\n",
    "    dwi_values = dwi_scaled[mask, ...].ravel()\n",
    "    dwi_values = dwi_values[dwi_values > 0]              # drop any sneaky zeros\n",
    "    mean       = dwi_values.mean()\n",
    "    std        = dwi_values.std() + 1e-6\n",
    "    dwi_norm   = (dwi_scaled - mean) / std\n",
    "\n",
    "    # 6) Return the normalised data plus the stats for reproducibility\n",
    "    return dwi_norm.astype(np.float32)\n",
    "\n",
    "\n",
    "def process_session(dwi_path: Path):\n",
    "    \"\"\"\n",
    "    Process a single 4-D DWI session and cache its 3-D gradient volumes.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dwi_path : pathlib.Path\n",
    "        Path to the cleaned 4-D DWI NIfTI file (shape [X, Y, Z, N]).\n",
    "\n",
    "    Steps\n",
    "    -----\n",
    "    1) Derive the matching .bval and .bvec file paths.\n",
    "    2) Parse patient ID (sub-XXX) and session ID (ses-YYY) from the filename.\n",
    "    3) Create an output directory at CACHE/sub-XXX/ses-YYY/.\n",
    "    4) Load the raw 4-D DWI data and corresponding b-values.\n",
    "    5) Load the .bval file containing the b-values for each gradient.\n",
    "    6) Normalize the entire volume (session-level gain + z-score).\n",
    "    7) Split the normalized 4-D volume into N individual 3-D gradient arrays and save each gradient as a compressed .npz containing:\n",
    "        - vol_data: 3-D image array\n",
    "        - bval: single float b-value\n",
    "        - bvec: 3-D b-vector (if available, currently not used)\n",
    "        - affine: 4 x 4 spatial transform\n",
    "        - patient, session tags\n",
    "    \"\"\"\n",
    "\n",
    "    # 1) Derive file stems for .bval and .bvec\n",
    "    #    We strip off the trailing \".nii.gz\" by slicing off 7 chars\n",
    "    base      = dwi_path.with_suffix(\"\").with_suffix(\"\")  # remove .nii.gz (with_suffix only removes one suffix at a time)\n",
    "    bval_path = base.with_suffix(\".bval\")\n",
    "    bvec_path = base.with_suffix(\".bvec\")\n",
    "\n",
    "    # 2) Extract patient & session IDs from the BIDS-style filename\n",
    "    #    Filename looks like \"sub-XXX_ses-YYY_dwi_allruns.nii.gz\"\n",
    "    p_id = base.name.split(\"_\")[0]  # e.g. \"sub-0001\"\n",
    "    s_id = base.name.split(\"_\")[1]  # e.g. \"ses-01\"\n",
    "\n",
    "    # 3) Prepare the output folder for this session\n",
    "    #    e.g. cache/sub-0001_ses-01/\n",
    "    out_dir = CACHE / p_id / s_id\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # 4) Load the 4-D DWI image (keeps affine + header for later)\n",
    "    dwi_img = nib.load(dwi_path)                             # nibabel Nifti1Image\n",
    "    dwi_raw = dwi_img.get_fdata().astype(np.float32)         # (X, Y, Z, N)\n",
    "\n",
    "    # 5) Load acquisition metadata\n",
    "    #    .bval: one row of N diffusion weightings\n",
    "    #    .bvec: 3×N axis vectors\n",
    "    bvals = np.loadtxt(bval_path)                            # shape (N,)\n",
    "    # bvecs = np.loadtxt(bvec_path)                            # shape (3, N)\n",
    "\n",
    "    # 6) Normalize the 4-D data with our robust session-level function\n",
    "    #    Returns the normalized array\n",
    "    dwi_norm = normalise_dwi(dwi_raw, bvals)\n",
    "\n",
    "    # 7) Split the normalized 4-D volume into individual 3-D gradient volumes\n",
    "    #    and save each as a compressed .npz with all relevant metadata.\n",
    "    for g in range(dwi_norm.shape[3]):\n",
    "        vol_data = dwi_norm[..., g]  # 3-D array (X, Y, Z)\n",
    "\n",
    "        out_file = out_dir / f\"{p_id}_{s_id}_grad{g:03d}.npz\"\n",
    "        np.savez_compressed(\n",
    "            out_file,\n",
    "            vol_data=vol_data,                          # 3D gradient volume (X, Y, Z)\n",
    "            bval=np.float32(bvals[g]),                  # single b-value for this gradient\n",
    "            # bvec=np.float32(bvecs[:, g]),             # 3D b-vector for this gradient TODO: bvecs are wrongly concatenated over runs\n",
    "            affine=dwi_img.affine.astype(np.float32),   # preserves spatial orientation for nifti reconstruction\n",
    "            patient=p_id,                               # for downstream grouping or sampling\n",
    "            session=s_id                                # ditto\n",
    "        )\n",
    "\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "for dwi_file in tqdm(find_sessions(Path(ROOT))):\n",
    "    process_session(dwi_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99739930",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10431 cached gradient files in /home/spieterman/dev/projects/dwi-transformer/data/encoder\n",
      "Dataset size: 10431\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class AEVolumes(Dataset):\n",
    "    def __init__(self, cache_root: str):\n",
    "        # 1) Find all cached gradient files\n",
    "        self.files = sorted(Path(cache_root).rglob(\"*grad*.npz\"))\n",
    "\n",
    "        # 2) Preload metadata for sampling weights\n",
    "        self.patients = []\n",
    "        self.sessions = []\n",
    "        self.bvals    = []\n",
    "        for f in self.files:\n",
    "            data = np.load(f)\n",
    "            # Extract scalar metadata\n",
    "            self.patients.append(data[\"patient\"].item())  # e.g. \"sub-0001\"\n",
    "            self.sessions.append(data[\"session\"].item())  # e.g. \"ses-01\"\n",
    "            self.bvals.append(float(data[\"bval\"].item()))\n",
    "        \n",
    "        print(f\"Found {len(self.files)} cached gradient files in {cache_root}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # 1) Load the .npz\n",
    "        data = np.load(self.files[idx])\n",
    "\n",
    "        # 2) Volume: [1, X, Y, Z]\n",
    "        vol = torch.from_numpy(data[\"vol_data\"]).unsqueeze(0).float()\n",
    "\n",
    "        # 3) Acquisition metadata\n",
    "        bval = torch.tensor(float(data[\"bval\"].item()), dtype=torch.float32)\n",
    "        # bvec = torch.from_numpy(data[\"bvec\"].astype(np.float32))\n",
    "\n",
    "        # 4) Spatial metadata\n",
    "        affine = torch.from_numpy(data[\"affine\"].astype(np.float32))  # [4, 4]\n",
    "\n",
    "        # 5) Provenance tags\n",
    "        patient = data[\"patient\"].item()  # string\n",
    "        session = data[\"session\"].item()  # string\n",
    "\n",
    "        return {\n",
    "            \"vol\":     vol,\n",
    "            \"bval\":    bval,\n",
    "            # \"bvec\":    bvec,\n",
    "            \"affine\":  affine,\n",
    "            \"patient\": patient,\n",
    "            \"session\": session,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b40632be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10431 cached gradient files in /home/spieterman/dev/projects/dwi-transformer/data/encoder\n",
      "[0.0018792282635930846, 0.0026959022286125087, 0.0028005974607916355, 0.0026959022286125087, 0.003770739064856712, 0.0026959022286125087, 0.0013448090371167296, 0.0015719974848040243, 0.0014755065905961047, 0.0013479511143062544]\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter, defaultdict\n",
    "import torch\n",
    "from torch.utils.data import WeightedRandomSampler, DataLoader\n",
    "\n",
    "def make_balanced_sampler(dataset: AEVolumes) -> WeightedRandomSampler:\n",
    "    \"\"\"\n",
    "    Build a sampler whose per-sample weight is\n",
    "\n",
    "        w(p,s,b) = 1 / |S_p| * 1 / m_{p,s} * |B| / k_b\n",
    "\n",
    "    where\n",
    "        |S_p|     = number of sessions for patient p\n",
    "        m_{p,s}   = number of volumes in session s of patient p\n",
    "        k_b       = total volumes in shell b  (across entire dataset)\n",
    "        |B|       = number of distinct shells\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    WeightedRandomSampler\n",
    "        Can be fed into DataLoader(..., sampler=sampler)\n",
    "    \"\"\"\n",
    "\n",
    "    # 1.  Gather per-sample metadata already stored by the Dataset\n",
    "    patients = dataset.patients        # list len = len(dataset)\n",
    "    sessions = dataset.sessions        # e.g. \"ses-d0757\"\n",
    "    bvals    = dataset.bvals           # float or int\n",
    "\n",
    "    # Create a composite session key \"sub-XXX_ses-YYY\"\n",
    "    sess_keys = [f\"{p}_{s}\" for p, s in zip(patients, sessions)]\n",
    "\n",
    "    # 2.  Pre-compute the three count tables\n",
    "    #   a. how many sessions per patient  |S_p|\n",
    "    patient_to_sessions = defaultdict(set)\n",
    "    for p, s in zip(patients, sessions):\n",
    "        patient_to_sessions[p].add(s)\n",
    "    S_counts = {p: len(sset) for p, sset in patient_to_sessions.items()}\n",
    "\n",
    "    #   b. how many volumes in each session  m_{p,s}\n",
    "    sess_counts = Counter(sess_keys)               # m_{p,s}\n",
    "\n",
    "    #   c. how many volumes in each shell  k_b\n",
    "    shell_counts = Counter(bvals)                  # k_b\n",
    "    B = len(shell_counts)                          # |B|\n",
    "\n",
    "    # 3.  Build the per-sample weight list\n",
    "    weights = []\n",
    "    for p, s, key, b in zip(patients, sessions, sess_keys, bvals):\n",
    "        w =  (1.0 / S_counts[p])          # patient balance\n",
    "        w *= (1.0 / sess_counts[key])     # session balance\n",
    "        w *= (B   / shell_counts[b])      # shell balance\n",
    "        weights.append(w)\n",
    "\n",
    "    print(weights[:10])  # debug: show first 10 weights\n",
    "\n",
    "    # 4.  Wrap in a WeightedRandomSampler\n",
    "    return WeightedRandomSampler(\n",
    "        weights=torch.DoubleTensor(weights),\n",
    "        num_samples=len(weights),     # one \"epoch\" = same expected size as dataset\n",
    "        replacement=True              # draw with replacement → true probability sampling\n",
    "    )\n",
    "\n",
    "\n",
    "# TODO: Validate the sampler mathematically\n",
    "ds = AEVolumes(cache_root=CACHE)\n",
    "sampler = make_balanced_sampler(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c935f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = next(iter(dl)).to(DEVICE)\n",
    "for name, maker in MODEL_REGISTRY.items():\n",
    "    model = maker()\n",
    "    recon, z = model(x)\n",
    "    print(f\"{name:6} → recon shape: {tuple(recon.shape)}, latent shape: {tuple(z.shape)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ea4410",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, loader, optimizer, criterion):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    for batch in loader:\n",
    "        batch = batch.to(DEVICE)\n",
    "        recon, _ = model(batch)\n",
    "        loss = criterion(recon, batch)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item() * batch.size(0)\n",
    "    return total_loss / len(loader.dataset)\n",
    "\n",
    "def validate_epoch(model, loader, criterion):\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            batch = batch.to(DEVICE)\n",
    "            recon, _ = model(batch)\n",
    "            val_loss += criterion(recon, batch).item() * batch.size(0)\n",
    "    return val_loss / len(loader.dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3021e065",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "results = []\n",
    "for model_name in [\"custom\", \"monai\"]:  # add \"resnet\" once ready\n",
    "    print(f\"\\n=== Training {model_name} AE ===\")\n",
    "    model = MODEL_REGISTRY[model_name]()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    logs = {\"epoch\": [], \"train_loss\": [], \"val_loss\": []}\n",
    "    for epoch in range(1, EPOCHS+1):\n",
    "        tr = train_epoch(model, dl, optimizer, criterion)\n",
    "        vl = validate_epoch(model, dl, criterion)\n",
    "        logs[\"epoch\"].append(epoch)\n",
    "        logs[\"train_loss\"].append(tr)\n",
    "        logs[\"val_loss\"].append(vl)\n",
    "        print(f\"Epoch {epoch:02d} | train: {tr:.4f} | val: {vl:.4f}\")\n",
    "    df = pd.DataFrame(logs)\n",
    "    df[\"model\"] = model_name\n",
    "    results.append(df)\n",
    "results_df = pd.concat(results, ignore_index=True)\n",
    "results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4ed42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.lineplot(data=results_df, x=\"epoch\", y=\"train_loss\", hue=\"model\", marker=\"o\")\n",
    "sns.lineplot(data=results_df, x=\"epoch\", y=\"val_loss\",   hue=\"model\", marker=\"x\", linestyle=\"--\")\n",
    "plt.title(\"AE Reconstruction Loss by Model\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66124a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MODEL_REGISTRY[\"custom\"]()  # or “monai”\n",
    "model.eval()\n",
    "sample = next(iter(dl))[0].unsqueeze(0).to(DEVICE)  # single volume\n",
    "with torch.no_grad():\n",
    "    recon, _ = model(sample)\n",
    "\n",
    "# show middle slice\n",
    "slice_idx = IMG_SHAPE[2] // 2\n",
    "fig, axes = plt.subplots(1,2, figsize=(8,4))\n",
    "axes[0].imshow(sample.cpu().numpy()[0,0,:,:,slice_idx], cmap=\"gray\")\n",
    "axes[0].set_title(\"Input\")\n",
    "axes[1].imshow(recon.cpu().numpy()[0,0,:,:,slice_idx], cmap=\"gray\")\n",
    "axes[1].set_title(\"Reconstruction\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
